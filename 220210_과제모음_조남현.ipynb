{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import urllib.request as req\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [과제] 네이버 홈페이지에 있는 ['메일','카페','블로그','지식IN','쇼핑']을 출력하세요.\n",
    "\n",
    "# 직접적인 방법 (무의미)\n",
    "URL = 'https://www.naver.com'\n",
    "content = requests.get(URL).text\n",
    "li = ['메일','카페','블로그','지식iN','쇼핑']\n",
    "a = []\n",
    "for i in li: \n",
    "    a.append(re.search(i,content).group())\n",
    "print(a)\n",
    "\n",
    "# 구하려는 각 element들은 다음과 같이 구성되어있음\n",
    "# <li class=\"nav_item\">\n",
    "# <a href=\"https://mail.naver.com/\" class=\"nav\" data-clk=\"svc.mail\"><i class=\"ico_mail\"></i>메일</a>\n",
    "# </li>\n",
    "\n",
    "b = []\n",
    "for i in range(5):\n",
    "    result = content.split('<li class=\"nav_item\">')[i+1]\n",
    "    word = re.search('[가-힣]+[a-zA-Z]*',result)\n",
    "    b.append(word.group())\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [과제] wf 태그는 모두 출력\n",
    "url = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\"\n",
    "res = req.urlopen(url)\n",
    "soup = BeautifulSoup(res,'html.parser')\n",
    "wf0 = soup.find('wf').text\n",
    "text = ''.join(re.findall('[^A-Z0-9]?[0-9가-힣]+[^A-Z0-9]?',wf0))\n",
    "wf = soup.find_all('wf')\n",
    "print(text,'\\n')\n",
    "for i in range(1,len(wf)):\n",
    "    print(wf[i].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [과제] 네이버 영화 조회순 랭킹 가져와서 첫번째 영화제목을 출력하세요\n",
    "url = 'https://movie.naver.com/movie/sdb/rank/rmovie.naver?sel=cnt&date=20220208'\n",
    "res = requests.get(url).text\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "# movie_top1 = soup.select_one('div.tit3 > a')      # 이 방법도 가능\n",
    "#old_content > table > tbody > tr:nth-child(2) > td.title > div > a         << 1위의 css collecter\n",
    "movie_top1 = soup.select_one('#old_content > table > tbody > tr:nth-child(2) > td.title > div > a')\n",
    "movie_top1.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [과제] 네이버 영화 조회순 랭킹 가져와서 전체 영화제목을 출력하세요\n",
    "url = 'https://movie.naver.com/movie/sdb/rank/rmovie.naver?sel=cnt&date=20220208'\n",
    "res = requests.get(url).text\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "# movie_top1 = soup.select_one('div.tit3 > a')      # 이 방법도 가능\n",
    "#old_content > table > tbody > tr:nth-child(3) > td.title > div > a         << 어떤 영화제목의 css collecter\n",
    "movie_top20 = soup.select('#old_content > table > tbody > tr > td.title > div > a') # 공통 경로로 써주기 위해 tr의 뒷부분 제거\n",
    "for i in movie_top20:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [과제] 기상청 육상 정보에서 강원도의 지역번호는 105이다. 강원도의 날씨예보를 출력하세요.\n",
    "url = 'https://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp?stnId=105'\n",
    "res = req.urlopen(url)\n",
    "soup = BeautifulSoup(res,'html.parser')\n",
    "wf = soup.find('wf').text\n",
    "text = re.sub('<br />\\*?','',wf)\n",
    "text = re.sub('(  )+','',text)\n",
    "text = text.split('○')\n",
    "for i in range(1,len(text)):\n",
    "    print(text[i],'\\n')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
